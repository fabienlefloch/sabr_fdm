\documentclass[]{rAMF2e}
%\usepackage[square]{natbib}
%\usepackage{authblk}
\usepackage{listings}
\usepackage[center]{caption}


\begin{document}
\doi{}
\issn{}  \issnp{}
\jvol{00} \jnum{00} \jyear{2013} %\jmonth{January--March}
\def\jobtag{}
\publisher{Unpublished}
\jname{}

\markboth{Fabien {Le Floc'h}, Gary Kennedy}{Draft}

\title{Finite Difference Techniques for Arbitrage Free SABR}
\author{Fabien {Le Floc'h}$^\star$\thanks{{\em{Correspondence Address}}: Calypso Technology, 106 rue de La Bo\'{e}tie, 75008 Paris. Email: \texttt{fabien\_lefloch@calypso.com} \vspace{6pt}} and Gary Kennedy$^\dag$}
\affil{$^\star$Calypso Technology, 106 rue de La Bo\'{e}tie, 75008 Paris\\$^\dag$Clarus Financial Technology, London}
%
\date{\today}
\received{v3.0 released January 2014}

\maketitle
\newcommand{\sgn}{\mathop{\mathrm{sgn}}}
\begin{abstract}
This paper presents various finite difference schemes applied to the SABR arbitrage free density problem with a focus on stability and speed.
\begin{keywords}stochastic volatility, SABR, TR-BDF2, Crank-Nicolson, finite difference, finance\end{keywords}
\end{abstract}

\section{Introduction}
It is now well known that original SABR analytic formula from \citep{hagan2002managing} used to compute option implied volatility is not arbitrage free as the probability density can become negative for low strikes and long maturities. Given the current low rates environment, many authors have proposed various improvements to the original formula \citep{obloj2008fine, johnson2009arbitrage, paulot2009asymptotic, benaim2008arbitrage}.  A single step finite difference method is proposed in \citep{andreasen2011zabr} which leads to an arbitrage free `SABR-like' model. Whilst the approach from Andreasen and Huge converges for short maturities to the original SABR analytic formula, it is (deliberately) different for longer expiries, even at the money.

Hagan recently proposed a new arbitrage free SABR solution, based on a finite difference discretisation of the probability density in \citep{hagan2013arbitrage}. This approach provides a solution very close to the original SABR analytic formula, well known and widely used, while being arbitrage free, and thus allowing pricing with low rates. The authors use a Crank-Nicolson time-stepping scheme, which is known to have oscillation issues \citep{duffy2004critique,GiCa2006} as it is only $A$-stable but not $L$-stable \citep{Le07}. We will show that this issue arises in the context of SABR pricing, and propose alternative schemes that are not very well known in computational finance, and yet are effective on this problem. One such scheme is TR-BDF2, used in the semiconductor industry as well as more generally in computational physics \citep{bank1985transient,bathe2005composite,edwards2011nonlinear, flavell2013conservative}. Another scheme is due to Lawson and Swayne; whilst somewhat obscure, it is simple and effective on this problem \citep{lawson1976simple}.  

Speed and accuracy were key ingredients in popularising the original SABR formula. Given that for a 30 year cap on a 3M LIBOR, there are potentially 119 PDEs to solve, we will focus our attention on the performance of the proposed schemes, as well as to what extent the discretisation grid can be reduced in size.



\section{Arbitrage Free SABR}
In \citep{hagan2013arbitrage}, pricing with SABR parameters $\alpha, \beta, \rho, \nu$ and forward $f$ at $\tau_{ex}$ relies on the solution of the Fokker-Planck PDE on the probability density $Q$:

\begin{align}\label{eqn_pde}
\frac{\partial Q}{\partial T}(T,F) = \frac{\partial^2 M(T,F) Q(T,F)}{\partial F^2} \text{ and } \begin{cases}
\frac{\partial Q_L}{\partial T}(T) = \lim_{F \to F_{\min}} \frac{\partial M(T,F) Q(T,F)}{\partial F}\\
\frac{\partial Q_R}{\partial T}(T) = \lim_{F \to F_{\max}} \frac{\partial M(T,F) Q(T,F)}{\partial F}
\end{cases}
\end{align}
with
\begin{alignat}{3}
M(T,F) = \frac{1}{2} D^2(F) E(T,F) \text{, } E(T,F) = e^{\rho\nu\alpha\Gamma(F) T} \text{, } \Gamma(F) = \frac{F^{\beta}-f^{\beta}}{F-f}\\
D(F) = \sqrt{\alpha^2 +2\alpha\rho\nu y(F)+ \nu^2 y(F)^2} F^{\beta} \text{, } y(F) = \frac{F^{1-\beta}-f^{1-\beta}}{1-\beta}
\end{alignat}
and initial condition 
\begin{equation}
\lim_{T \to 0} Q(T,F) = \delta (F - f)
\end{equation}

Vanilla option prices can then be computed through the Breeden-Litzenberger formula \citep{breeden1978prices}:
\begin{align}
V_{call} (T, K) &= \int_{K}^{F_{\max}} (F-K) Q(T,F) dF + (F_{\max} - K) Q_R(T) \\
V_{put} (T, K) &= (K-F_{\min}) Q_L(T) + \int_{F_{\min}}^{K} (K-F) Q(T,F) dF 
\end{align}

$M(T,F)$ represents the diffusion coefficient, which makes $D(F)\sqrt{E(T,F)}$ the normal local volatility in financial terms. In \citep{andreasen2011zabr}, a slightly simpler (less accurate for long maturities) expansion of the local volatility is found and directly used in the normal Dupire forward PDE on the call prices $V_{call}$:
\begin{equation}\label{eqn:forward-dupire}
\frac{\partial V_{call}}{\partial T}(T,F) = \frac{1}{2}\vartheta^2(T,F) \frac{\partial^2 V_{call}}{\partial F^2}(T,F)
\end{equation} 
with initial condition $V_{call}(0, F) = (f-F)^{+}$ and
\begin{equation}
\vartheta(T, F) = D(F)
\end{equation}

Both approaches are strikingly similar if the same local volatility approximation as well as the same PDE discretization is used. One difference lies in the boundary conditions: Hagan uses an absorbing condition at $F_{\min}$ and $F_{\max}$, while Andreasen and Huge use the standard Hagan expansion formula at the boundaries. It is also possible to use the more classic linear boundaries condition in the Dupire forward PDE, which is even closer, then to an absorbing condition in the probability density.

While our will focus is mainly on the PDE in probability density, we will also have a quick look at the nearly equivalent Dupire representation in order to find out if one approach is more efficient or not.

\section{Change of Variable}
\subsection{Transformation of the Fokker-Planck PDE}
One practical difficulty that arises with the Arbitrage Free PDE described in equations (\ref{eqn_pde}) is the choice of $F_{max}$. \citet{hagan2013arbitrage} proposes a formula to estimate the required $F_{max}$, that, for some parameters is not suitable. It can be very large for long term deals and as a consequence the discretization requires a very large number of points to obtain an acceptable accuracy. The technique becomes inefficient. However, this type of problem is not new and a common approach is to consider a change of variable as a remedy \citep[p. 292 section 7.4]{andersen2010interest}. On this particular problem the following change of variable works well whilst still preserving the moments \citep{hagan2013change}:
\begin{align}\label{eqn-variable-transform}
z(F) &= \int_{f}^F \frac{dF'}{D(F')}
\end{align}
This leads to a PDE in $\theta(z) = Q(T,F(z))D(F(z)) = Q(T,F(z))C(z)$ with $C(z) = D(F(z))$:
\begin{align}\label{eqn-transform-pde}
\frac{\partial \theta}{\partial T}(T,z) = \frac{1}{2} \frac{\partial}{\partial z} \left\lbrace \frac{1}{C(z)} \frac{\partial C(z)E(T,z)\theta(T,z)}{\partial z} \right\rbrace
 \text{ and } \begin{cases}
\theta(T,z) = 0 \text{ as } z \to z^{-}=z(F_{\min})\\
\theta(T,z) = 0 \text{ as } z \to z^{+}=z(F_{\max})
\end{cases}
\end{align}
with \begin{align}
\label{eqn-y(z)}
y(z) &= \frac{\alpha}{\nu}\left[ \sinh(\nu z) + \rho (\cosh(\nu z) - 1) \right]\\ 
\label{eqn-F(z)}
F(y) &= \left[ f^{1-\beta} + (1-\beta)y \right]^{\frac{1}{1-\beta}}
\end{align}

The probability at the boundaries accumulates according to:
\begin{align}\label{eqn-transform-boundary}
\frac{\partial P_L}{\partial T}(T) &= \lim_{z \to z^{-}} \frac{1}{2} \frac{1}{C(z)} \frac{\partial C(z)E(T,z)\theta(T,z)}{\partial z}\\
\frac{\partial P_R}{\partial T}(T) &= \lim_{z \to z^{+}}  -\frac{1}{2} \frac{1}{C(z)} \frac{\partial C(z)E(T,z)\theta(T,z)}{\partial z}
\end{align}

As a result, the effect of the diffusion term $D$ has almost been cancelled, and the probability density $\theta$ is closer to a Gaussian in $z$. $z^+$ and $z^-$ are then naturally chosen to be $\pm n_{sd}\sqrt{\tau_{ex}}$, corresponding to $n_{sd}$ standard deviations above and below the forward located at $z=0$ (taking care of truncating at the barrier $F=0$ if necessary). Figure \ref{fig:Fz} shows that the probability density will be computed with a high concentration of points around the forward, and a much lower one near the upper boundary.

\begin{figure}[htb]
  \begin{center}  
    \includegraphics[width=6cm]{fz.eps}
  \end{center}
     \caption{\label{fig:Fz} $F(z)$ with $\alpha=35\%, \beta=0.25, \rho=-10\%, \nu=100\%, \tau_{ex}=1$}
\end{figure}

The call and put prices are obtained by integrating on the transformed density:
\begin{align}
V_{call} (T, K) &= \int_{z(K)}^{z^{+}} (F(z)-K) \theta(T,z) dz + (F_{\max} - K) P_R(T) \\
V_{put} (T, K) &= (K-F_{\min}) P_L(T) + \int_{z^{-}}^{z(K)} (K-F(z)) \theta(T,z) dz
\end{align}


For some extreme SABR parameters, the change of variable allows high accuracy with a small number of points. The uniform discretization of $Q$ in $F$ can require approximately 1000 times more points to reach a similar accuracy (Table \ref{table:discretization}).
\begin{table}[h]
\begin{center}
\begin{tabular}{|c|r|r|r|r|}
	\hline
\multicolumn{5}{|c|}{Uniform discretization of $Q$ in $F$} \\ \hline
$F_{max}$ & Points & Steps & Price & Vol \\
5 & 10 & 5 & 0.65010 & 87.205  \\
50 & 100 & 10 & 0.78769 & 155.773\\
500 & 1000 & 20 & 0.79782 & 191.658 \\
5000 & 10000 & 160 & 0.79835 & 196.930\\
\hline
\end{tabular}
\begin{tabular}{|c|r|r|r|r|}
\hline
\multicolumn{5}{|c|}{Discretization of $\theta$ in $z$} \\ \hline
$n_{sd}$ & Points & Steps & Price & Vol\\
3 & 10 & 5 & 0.79848 & 198.504\\
3 & 100 & 10 & 0.79853 & 199.148\\
4 & 100 & 20 & 0.79847 & 198.338\\
10 & 10000 & 160 & 0.79845 & 198.134\\
\hline
\end{tabular}
\caption{\label{table:discretization}Price by the Lawson-Swayne method without and with variable change for extreme SABR parameters: $\alpha=100\%, \beta=0.30, \rho=90\%, \nu=100\%, \tau_{ex}=10, f=1$}
\end{center}
\end{table} 
The number of points used can not be too small: the forward should not be on the boundary. This restriction is much stricter for the uniform discretization of $Q$ than for the discretization in the changed variable $\theta$.

\subsection{Coordinate Transformation for the Forward Dupire PDE}
The same variable transformation (\ref{eqn-variable-transform}) can be applied to the Dupire PDE resulting in:
\begin{equation}
\frac{\partial V_{call}}{\partial T}(T,z) = \frac{1}{2} \frac{\partial}{\partial z} \left\lbrace \frac{1}{C(z)} \frac{\partial C(z)E(T,z)V_{call}(T,z)}{\partial z} \right\rbrace
\end{equation}

with initial condition $V_{call}(0, z) = (f - F(z))^+$.

A slightly simpler alternative approach consists in using an equivalent non-uniform grid in $F$ inside a finite difference discretization of the forward Dupire PDE (\ref{eqn:forward-dupire}) as described in \citep{andersen2010interest}. The equivalent non uniform grid is defined by $F(z)$ where $z$ is a uniform discretization. Care must be taken to place the forward $f$ in the middle of two nodes in order to decrease the numerical error \citep{tavella-pricing}. Another technique to reduce the numerical error is to smooth out the payoff at maturity by averaging, but this would not preserve put-call parity \citep{lefloch2013exacttr}.

Let's define a uniform grid in the coordinate $z$, for $j=0,...,J+1$:
\begin{alignat}{2}
z_j &= z^{-} + j h \text{ , } h = \frac{1}{J+1}(z^{+}-z^{-})
\end{alignat}
Using Equations (\ref{eqn-y(z)}) and (\ref{eqn-F(z)}), the corresponding grid in $F$ would be:
\begin{equation}
F_j = F\left(y(z_j)\right)  = F\left( y\left(z^{-} + \frac{j}{J+1}\left(z^{+}-z^{-}\right)\right)  \right)
\end{equation}
To place the forward $f$ in the middle of two consecutive points, we first locate the index $j_0$ so that 
$F_{j_0} \leq f < F_{j_0 + 1}$, that is:
\begin{equation}
j_0 = \lfloor\frac{z(y(f)) - z^{-}}{h}\rfloor
\end{equation}
And then we shift the grid by a distance $d$ defined by:
\begin{equation}
d = z(y(f))  - z(y\left(\frac{1}{2}(F_{j_0}+F_{j_0+1})\right))
\end{equation}
The new grid is then just generated via 
\begin{equation}
\tilde{F}_j = F(y(z_{0}+ j h + d)) = F(y( z^{-} + \frac{j}{J+1}\left(z^{+}-z^{-}\right) + z(y(f))  - z(y\left(\frac{1}{2}(F_{j_0}+F_{j_0+1})\right)) )) 
\end{equation}
In addition, we make sure to keep the original boundaries, this is especially important as $z^{-}$ often corresponds to the absorbing barrier by forcing $\tilde{F}_0 = F(y(z^{-}))$ and $\tilde{F}_{J+1} = F(y(z^{+}))$.

Finally, to compute the price of an option in between two grid nodes, we interpolate the discrete prices using a natural cubic spline in order to preserve the second derivative continuity (and therefore the probability density continuity) everywhere.
 
\section{Discretization of the the PDE in $\theta$}
Let's define for $j=1,...,J$:
\begin{alignat}{3}
z_j &= z^{-} + jh \text{ , } \hat{y}_j&=y(z_j - \frac{1}{2}h) \text{ , } \hat{F}_j&=F(\hat{y}_j)\\
\hat{C}_j&=D(\hat{F}_j) \text{ , } \hat{\Gamma}_j &= \frac{{\hat{F}_j}^{\beta}-f^{\beta}}{\hat{F}_j-f} \text{ , } \hat{E}_j(T)&=e^{\rho\nu\alpha\hat{\Gamma}_j T}
\end{alignat}

We also define for $n=0,...,N-1$
\begin{align}
t_n &= n \delta \text{ with } \delta = \frac{\tau_{ex}}{N} \\
\theta_j^n &= \theta(z_j,t_n)
\end{align}

To preserve the zero-eth and first moment of $F$, the PDE (Equation \ref{eqn-transform-pde}) is discretized in $z$ as \citep{hagan2013change}:
\begin{align}
\frac{\partial \theta}{\partial T}(z, t_n) &= \mathcal{L}_{j}^n \theta(z, t_n)
\end{align}
for $j=1,...,J$ with $\mathcal{L}_{j}^n$ the discrete operator defined by
\begin{align}
  \mathcal{L}_{j}^n\theta(z_j, t_n) &= \frac{1}{h} \frac{\hat{C}_{j-1}}{\hat{F}_{j}-\hat{F}_{j-1}}\hat{E}_{j-1}(t_n)\theta(z_{j-1},t_n)\\
  &-\frac{1}{h}\left(\frac{\hat{C}_{j}}{\hat{F}_{j+1}-\hat{F}_j}+\frac{\hat{C}_{j}}{\hat{F}_{j}-\hat{F}_{j-1}}\right)\hat{E}_{j}(t_n)\theta(z_j,t_n)\\
  &+\frac{1}{h}\frac{\hat{C}_{j+1}}{\hat{F}_{j+1}-\hat{F}_j}\hat{E}_{j+1}(t_n)\theta(z_{j+1},t_n)
\end{align}
and for the boundaries at $j=0$ and $j=J+1$:
\begin{subequations}\label{eqn:boundary_theta}
\begin{align}
\frac{\hat{C}_0}{\hat{F}_1-\hat{F}_0}\hat{E}_0(T) \theta(z_0,T) &= - \frac{\hat{C}_1}{\hat{F}_1-\hat{F}_0}\hat{E}_1(T) \theta(z_1,T) \\
\frac{\hat{C}_{J+1}}{\hat{F}_{J+1}-\hat{F}_J}\hat{E}_{J+1}(T) \theta(z_{J+1},T) &= - \frac{\hat{C}_J}{\hat{F}_{J+1}-\hat{F}_{J}}\hat{E}_J(T) \theta(z_J,T)
\end{align}
\end{subequations}
The boundary condition described by equations (\ref{eqn:boundary_theta}) is applicable to all schemes considered in this section as it is independent of the time-stepping.

The probability accumulated at the boundaries is discretized as:
\begin{align}
\frac{\partial P_L}{\partial T} (T) &= \frac{\hat{C}_1}{\hat{F}_1-\hat{F}_0}\hat{E}_1(T)\theta(z_1, T) \\
\frac{\partial P_R}{\partial T} (T) &= \frac{\hat{C}_J}{\hat{F}_{J+1}-\hat{F}_J}\hat{E}_J(T)\theta(z_J, T) 
\end{align}

The call and put prices are obtained by integrating with the mid-point method. Let $z^* = z(y(K))$. We first suppose that $z^{-} < z^* < z^{+}$. Let $k$ be the index such that $z^{-}+(k-1)h < z^* \leq z^{-}+k h$ and $F_k = F(y(z^{-}+kh))$. Then
\begin{align*}
V_{call} &= \frac{h}{4(F_k-\hat{F}_k)}(F_k - K)^2 \theta_k 
+ \sum_{j=k+1}^{J-1} (\hat{F}_j - K) h \theta_j 
+ (F_{\max}-K) P_R\\
V_{put} &= \frac{h}{4(\hat{F}_k-F_k)}(K-F_k)^2 \theta_k 
+ \sum_{j=1}^{k} (K-\hat{F}_j) h \theta_j 
+ (K-F_{\min}) P_L
\end{align*}
For the call option case, the first term corresponds to 
\begin{equation}
\int_{z^*}^{z_k}(F(z)-K)\theta(z)dz = \int_{K}^{F_k}(F-K)\frac{\theta(z(F))}{D(F)}dF
\end{equation}
 We then assume $\theta$ constant between $z_{k-1}$ and $z_{k}$, and make the approximation $D(F)=\frac{\partial F}{\partial z} \approx 2\frac{F_k-\hat{F}_k}{h}$ (we found that this choice preserved a smoother numerical density). The put option case is similar.


When $z^* \leq z^{-}$, $V_{call} = f-K$ and $V_{put} = 0$. When $z^* \geq z^{+}$, $V_{call} = 0$ and $V_{put} = K-f$.

\subsection{Moment Preserving Implicit Euler}
\begin{subequations}
\begin{align}
\theta_j^{n+1}-\theta_j^n &= \delta \mathcal{L}_{j}^{n+1} \theta_j^{n+1} \\
P_L (t_{n+1}) - P_L (t_{n}) &= \delta \frac{\hat{C}_1}{\hat{F}_1-\hat{F}_0}\hat{E}_1(t_{n+1})\theta_1^{n+1} \\
P_R (t_{n+1}) -  P_R (t_{n}) &= \delta \frac{\hat{C}_J}{\hat{F}_{J+1}-\hat{F}_J}\hat{E}_J(t_{n+1})\theta_J^{n+1}
\end{align}
\end{subequations}
for $j=1,...,J$ and $n=0,...,N-1$.

It is suggested that the lower boundary $F_{\min}$ for the standard SABR model is placed at or near zero. However, the finite difference grid described in Appendix C of their paper starts at  $F_0 = F_{\min} - \frac{h}{2}$, where, $h$ is the asset forward discretisation step size, potentially requiring the evaluation of functions not well-defined for negative values of $F_0$. Fortunately, only the product $M_0 Q_0$ is used in the discretisation of equation (\ref{eqn_pde}) and it is entirely defined by $M_1 Q_1$  because of the mirror-like boundary condition (imposed at the fictitious point $F_0$): 
\begin{align}\label{boundary_condition}
M_0 Q_0 + M_1 Q_1 &= 0
\end{align}
As long as $M_0 \neq 0$, $M_0 Q_0$ will take the value $-M_1 Q_1$. For example, we can use $|F_0|$ to compute $M_0$ and this will result in a symmetry around $F_{min}$.


Another alternative would be to place the grid so that $F_0 = F_{min}$ and use boundary condition $Q_0 = 0$ there. The probability of absorption $Q_L$ could then be evaluated using an forward finite difference first derivative estimate. This would result in the exact same equation as (C.10a) of their paper and the scheme would still be moment preserving. However this comes at a cost of a slight loss of accuracy as, effectively, the derivative will be estimated using $Q_1 = Q(h)$ instead of $Q_1 = Q(\frac{h}{2})$.

The formula for $\Gamma$ is also undefined for $F=f$, in which case we just use $\Gamma(f) = \frac{\partial C}{\partial F}(f)$.


\subsection{Moment Preserving Crank-Nicolson}
\begin{subequations}
\begin{align}\label{eqn_cn_1}
\theta_j^{n+1}-\theta_j^n &= \frac{\delta}{2} \left( \mathcal{L}_{j}^{n+1}\theta_j^{n+1} + \mathcal{L}_{j}^{n}\theta_j^{n} \right) \\
P_L (t_{n+1})- P_L (t_{n}) &= \frac{\delta}{2} \frac{\hat{C}_1}{\hat{F}_1-\hat{F}_0}\left(\hat{E}_1(t_{n+1})\theta_1^{n+1}+\hat{E}_1(t_{n})\theta_1^{n} \right)\\
P_R (t_{n+1})-P_R (t_{n}) &=  \frac{\delta}{2} \frac{\hat{C}_J}{\hat{F}_{J+1}-\hat{F}_J}\left(\hat{E}_J(t_{n+1})\theta_J^{n+1}+\hat{E}_J(t_{n})\theta_J^{n} \right)
\end{align}
\end{subequations}
for $j=1,...,J$ and $n=0,...,N-1$.

\section{Crank-Nicolson Oscillations with SABR}\label{section_cn}
\begin{figure}[htb]
  \begin{center}  
      \subfigure[PDE in $Q$ with 40 time steps and $F_{max}=5$]{\label{fig:density_hagan_cn_500_40}
\includegraphics[width=7cm]{density_hagan_cn_500_40s.eps}}
  \subfigure[PDE in $\theta$ with 80 time steps and $n_{sd}=4$]{\label{fig:density_hagan_cn_500_80}
\includegraphics[width=7cm]{density_hagan_cn_theta_500_80s.eps}}
  \end{center}
     \caption{\label{fig:density_hagan_cn_500_40} Probability density in Hagan PDE discretised with Crank-Nicolson with 500 points. $\alpha=35\%, \beta=0.25, \rho=-10\%, \nu=100\%, \tau_{ex}=1$}
\end{figure}

We use the same parameters as the example of negative density with the standard SABR formula in \citep{hagan2013arbitrage}: $\alpha=35\%, \beta=0.25, \rho=-10\%, \nu=100\%$ and forward $f=1$ at $\tau_{ex}=1$, a relatively fine discretisation in the rate dimension (500 points, that is $h = 0.01005$) and large time-steps (40 steps, that is $\delta=0.025$). \cite{hagan2013arbitrage} recommend between 200 and 500 points and 30 to 100 time-steps.

Figure \ref{fig:density_hagan_cn_500_40} shows strong oscillations around the forward. To guarantee the absence of oscillations, the \emph{Courant number}  should be small enough $\Psi \leq 1$ (Theorem 2.2 in \cite{morton2005numerical}). For the uniform discretization of $Q(F)$, $\Psi_Q = M \frac{\delta}{h^2}$. This corresponds directly to the stability of the explicit Euler part of Crank-Nicolson. In practice, a higher value is acceptable because of a slight damping in Crank-Nicolson \citep{lawson1978extrapolation}. Although $M$ depends on $F$, we can use the at-the-money value at $f$, as the spike is located there; that is, 
\begin{align}
\Psi_Q &= \frac{1}{2} \alpha^2 f^{2\beta} \frac{\delta}{h^2} \\
\Psi_{\theta} &= f^{\beta}\frac{\delta}{h^2} 
\end{align} 

\begin{figure}[htb]
  \begin{center}  
    \subfigure[with 40 time steps $\Psi_Q = 15.16$]{\label{fig:density_hagan_cn_500_40_5}
\includegraphics[width=7cm]{density_hagan_cn_500_40_5.eps}}
  \subfigure[with 1280 time steps $\Psi_Q = 0.47$]{\label{fig:density_hagan_cn_500_1280_5}
\includegraphics[width=7cm]{density_hagan_cn_500_1280_5.eps}}
  \end{center}
     \caption{\label{fig:density_hagan_500_40_5} First 4 time steps of the probability density in Hagan PDE discretised with Crank-Nicolson}
\end{figure}

In our example, in Figures \ref{fig:density_hagan_cn_500_40} and \ref{fig:density_hagan_cn_500_40_5} $\Psi_Q \approx 15$ while Figure \ref{fig:density_hagan_cn_500_1280_5} shows that indeed when $\Psi < 1$ there are no oscillations. The Crank-Nicolson oscillations are even stronger with the PDE in $\theta$ as for $\alpha \ll 1$, we have $\Psi_{\theta} \gg \Psi_Q$. Using the same SABR parameters and $n_{sd}=3$ (corresponding to $F_{max} \approx 5$), $\Psi_{\theta} \approx 250$. In the next sections it is shown that a much smaller number of time steps can be used with other finite difference time-stepping techniques whilst still preserving good accuracy.

\section{Alternative Schemes}
We will focus our analysis on the PDE in $\theta$, but similar conclusion can be drawn for the PDE in $Q$.

\subsection{Rannacher}
A common fix for Crank-Nicolson oscillations related to non smooth initial data is Rannacher time-stepping \citep{rannacher1984finite, pooley2003convergence, GiCa2006}. It consists of introducing two half time-steps of implicit Euler time-stepping before applying Crank-Nicolson, because implicit Euler has much stronger damping properties. This comes at a cost in accuracy as implicit Euler is an order-1 scheme in time, especially when only a few time-steps are needed.
The SABR density discretisation will still be moment preserving if we discretise the Euler half steps as:
\begin{subequations}\label{eqn_euler_1}
\begin{align}
\theta_j^{n+\frac{1}{2}}-\theta_j^n &= \frac{\delta}{2} \mathcal{L}_{j}^{n+\frac{1}{2}} \theta_j^{n+\frac{1}{2}} \\
P_L (t_{n+\frac{1}{2}}) - P_L (t_{n}) &=   \frac{\delta}{2} \frac{\hat{C}_1}{\hat{F}_1-\hat{F}_0}\hat{E}_1(t_{n+\frac{1}{2}})\theta_1^{n+\frac{1}{2}} \\
P_R (t_{n+\frac{1}{2}}) -  P_R (t_{n}) &=\frac{\delta}{2} \frac{\hat{C}_J}{\hat{F}_{J+1}-\hat{F}_J}\hat{E}_J(t_{n+\frac{1}{2}})\theta_J^{n+\frac{1}{2}}
\end{align}
\end{subequations}
for $j=1,...,J$ and $n = 0, \frac{1}{2}, 1, \frac{3}{2}$. The next steps are Crank-Nicolson for $n=2,...,N-1$.

\subsection{BDF2}
The second order backward difference scheme (BDF2) is $A$-stable and $L$-stable multistep implicit scheme and will therefore damp any oscillation very quickly. Multi-steps schemes have however severe limitations: instabilities will occur for sudden changes in the system variables, and initialization by another method is needed for the first steps \citep{windcliff2001shout}. For example they can not be applied to linear complimentary problems like the pricing of American options through the discretization of the Black-Scholes PDE \citep{lefloc2013tr}. Those issues don't arise with the SABR density PDE. The first moments will be preserved with the following discretization:
\begin{subequations}
\begin{align}
3\theta_j^{n+2}-4\theta_j^{n+1}+\theta_j^n &= 2 \delta \mathcal{L}_{j}^{n+2} \theta_j^{n+2} \\
3 P_L (t_{n+2}) - 4 P_L (t_{n+1}) + P_L (t_{n}) &=2 \delta \frac{\hat{C}_1}{\hat{F}_1-\hat{F}_0}\hat{E}_1(t_{n+2})\theta_1^{n+2} \\
3 P_R (t_{n+2}) - 4 P_R (t_{n+1}) +  P_R (t_{n}) &= 2\delta \frac{\hat{C}_J}{\hat{F}_{J+1}-\hat{F}_J}\hat{E}_J(t_{n+2})\theta_J^{n+2}
\end{align}
\end{subequations}
for $j=1,...,J$ and $n=0,...,N-2$. Implicit Euler is used to compute $\theta_j^1, P_L^1, P_R^1$ at $n=0$.

\subsection{Implicit Richardson Extrapolation}
A simple Richardson extrapolation in time \citep{richardson1911approximate} on implicit Euler will also provide a nearly order-2 scheme in time, keeping strong damping properties of the implicit Euler scheme at the cost of increased computational load: the implicit Euler scheme (equations \ref{eqn_euler_1}) is evaluated with $\frac{\delta}{2}$ and $\delta$. In practice it is around twice as slow as Crank-Nicolson. At $T=N\delta=\tau_{ex}$, we apply:
\begin{align}\label{eqn_richardson}
\theta(z) &= 2 \bar{\theta}^{\frac{\delta}{2}}(z) - \bar{\theta}^{\delta}(z) \\
P_L &= 2 \bar{P}^{\frac{\delta}{2}}_L - \bar{P}^{\delta}_L\\
P_R &= 2 \bar{P}^{\frac{\delta}{2}}_R - \bar{P}^{\delta}_R
\end{align}

where $\bar{\theta}^{\delta}, \bar{P}_L^{\delta}, \bar{P}_R^{\delta}$ are $\theta, P_L, P_R$ computed by implicit Euler with a time step of $\delta$.


\subsection{Lawson-Morris-Gourlay}
A local Richardson extrapolation in time of second and third order is proposed in \citep{lawson1978extrapolation} and \citep{gourlay1980extrapolation}. In practice, it is a faster alternative to the standard Richardson extrapolation because the tridiagonal matrix stemming out of the finite difference discretisation can be reused, while keeping $L$-stability and thus strong damping properties.

For the second order scheme, at each time-step, equation (\ref{eqn_richardson}) is applied.
For the third order scheme, at each time-step we apply:
%\begin{subequations}
\begin{align}\label{eqn_lmg3}
\theta(F) &= 4.5 \bar{\theta}^{\frac{\delta}{3}}(F) - 4.5 \bar{\theta}^{\frac{2\delta}{3}}(F)  + \bar{\theta}^{\delta}(F)\\
P_L &= 4.5 \bar{P}^{\frac{\delta}{3}}_L - 4.5 \bar{P}^{\frac{2\delta}{3}}_L  + \bar{P}^{\delta}_L\\
P_R &= 4.5 \bar{P}^{\frac{\delta}{3}}_R - 4.5 \bar{P}^{\frac{2\delta}{3}}_R  + \bar{P}^{\delta}_R
\end{align}
%\end{subequations}
where $\bar{\theta}^{\frac{\delta}{3}}$ is $\theta$ computed by implicit Euler with 3 time steps of $\frac{\delta}{3}$ and $\bar{\theta}^{\frac{2\delta}{3}}$ is $\theta$ computed by implicit Euler with a time step of $\frac{2\delta}{3}$ and $\frac{\delta}{3}$. Being linear combinations of implicit Euler, those schemes are moment preserving.

\subsection{Lawson-Swayne}
A slightly faster second order unconditionally stable scheme is presented as a remedy to Crank-Nicolson in \citep{lawson1976simple, lawson1978extrapolation}. Let $b=1-\frac{\sqrt{2}}{2}$, it consists in applying two implicit Euler steps with time-step of $b\delta$ and an extrapolation on the values at those two steps.\\
\\
First stage:
\begin{subequations}
\begin{align}\label{eqn_lawson_swayne}
\begin{split}
\theta_j^{n+b}-\theta_j^n &= b\delta \mathcal{L}_{j}^{n+b}\theta_j^{n+b} \\
P_L (t_{n+b}) - P_L (t_{n}) &=   b\delta \frac{\hat{C}_1}{\hat{F}_1-\hat{F}_0}\hat{E}_1(t_{n+b})\theta_1^{n+b} \\
P_R (t_{n+b}) -  P_R (t_{n}) &=b\delta \frac{\hat{C}_J}{\hat{F}_{J+1}-\hat{F}_J}\hat{E}_J(t_{n+b})\theta_J^{n+b}
\end{split}\\
\intertext{Second stage:}
\begin{split}
\theta_j^{n+2b}-\theta_j^{n+b} &= b\delta \mathcal{L}_{j}^{n+2b}\theta_j^{n+2b} \\
P_L (t_{n+2b}) - P_L (t_{n+b}) &=   b\delta \frac{\hat{C}_1}{\hat{F}_1-\hat{F}_0}\hat{E}_1(t_{n+2b})\theta_1^{n+2b} \\
P_R (t_{n+2b}) -  P_R (t_{n+b}) &=b\delta \frac{\hat{C}_J}{\hat{F}_{J+1}-\hat{F}_J}\hat{E}_J(t_{n+2b})\theta_J^{n+2b}
\end{split}\\
\intertext{And finally:}
\begin{split}
\theta_j^{n+1} &= (\sqrt{2}+1) \theta_j^{n+2b} - \sqrt{2}\theta_j^{n+b}\\
P_L(t_{n+1}) &= (\sqrt{2}+1) P_L(t_{n+2b}) - \sqrt{2} P_L(t_{n+b})\\
P_R(t_{n+1}) &= (\sqrt{2}+1)  P_R(t_{n+2b}) - \sqrt{2} P_R(t_{n+b})
\end{split}
\end{align}
\end{subequations}
for $j=1,...,J$ and $n=0,...,N-1$.

The scheme is moment preserving as it can also be seen as a linear combination of implicit Euler schemes.

\subsection{TR-BDF2}
TR-BDF2 is a two-stage method where the first stage consists in applying the (weighted) trapezoidal rule (Crank-Nicolson) and the second stage consists in applying the second order backward difference scheme (BDF2) on the first stage result and the first stage initial input \citep{bank1985transient, Le07}. It is second order accurate in time and $L$-stable. It is not to be confused with the simpler multistep method BDF2: the full step only depends on the previous full step while BDF2 depends on the two previous timesteps and can lose its accuracy \citep{windcliff2001shout} with variable timesteps and linear complimentary problems. This scheme does not suffer from such drawbacks. The scheme has been applied to finance in the context of American option pricing \citep{lefloch2013tr}.
\begin{subequations}
\begin{align}
\intertext{First stage:}\label{eqn_trbdf2}
\begin{split}
\theta_j^{n+\alpha}-\theta_j^n &= \frac{\alpha \delta}{2}\left( \mathcal{L}_{j}^{n+\alpha}\theta_j^{n+\alpha} +\mathcal{L}_{j}^{n}\theta_j^{n}  \right)\\
P_L (t_{n+\alpha}) &= P_L (t_{n}) +  b\delta \frac{\hat{C}_1}{\hat{F}_1-\hat{F}_0} \left( \hat{E}_1(t_{n+\alpha})\theta_1^{n+\alpha}+\hat{E}_1(t_{n})\theta_1^{n} \right)\\
P_R (t_{n+\alpha}) &=P_R (t_{n})+ b\delta \frac{\hat{C}_J}{\hat{F}_{J+1}-\hat{F}_J}\left( \hat{E}_J(t_{n+\alpha})\theta_J^{n+\alpha}+ \hat{E}_J(t_{n})\theta_J^{n} \right)
\end{split}\\
\intertext{Second stage:}
\begin{split}
\theta_j^{n+1} &= \frac{1}{2-\alpha}\left(\frac{1}{\alpha} \theta_j^{n+\alpha} - \frac{(1-\alpha)^2}{\alpha}\theta_j^n + \delta(1-\alpha) \mathcal{L}_j^{n+1} \theta_j^{n+1}\right)\\
P_L(t_{n+1}) &= \frac{1}{2-\alpha}\left(\frac{1}{\alpha} P_L(t_{n+\alpha}) - \frac{(1-\alpha)^2}{\alpha}P_L(t_n) + \delta(1-\alpha)  \frac{\hat{C}_1}{\hat{F}_1-\hat{F}_0} \hat{E}_1(t_{n+1})\theta_1^{n+1})\right)\\
P_R(t_{n+1}) &= \frac{1}{2-\alpha}\left(\frac{1}{\alpha} P_R(t_{n+\alpha}) - \frac{(1-\alpha)^2}{\alpha}P_R(t_n) + \delta(1-\alpha)  \frac{\hat{C}_J}{\hat{F}_{J+1}-\hat{F}_J} \hat{E}_J(t_{n+1})\theta_J^{n+1})\right)
\end{split}
\end{align}
\end{subequations}

The weight $\alpha$ can be chosen to match Crank-Nicolson ($\alpha=\frac{1}{2}$) or to have proportional Jacobians ($\alpha = 2-\sqrt{2}$). The later provides optimal stability \citep{dharmaraja2009optimal}. 

This can be extended to three-stages, with two stages of the trapezoidal rule and one stage of third order backward difference scheme (BDF3) as in \citep{bathe2005composite}, resulting in a method with even stronger damping properties that we will name ``Bathe'':
\begin{subequations}
\begin{align}
\theta_j^{n+\frac{1}{3}} &= \theta_j^n + \frac{\delta}{6}\left(\mathcal{L}_j^{n} \theta_j^n+\mathcal{L}_j^{n+\frac{1}{3}} \theta_j^{n+\frac{1}{3}}\right)\\
\theta_j^{n+\frac{2}{3}} &= \theta_j^n + \frac{\delta}{6}\left( \mathcal{L}_j^{n+\frac{1}{3}} \theta_j^{n+\frac{1}{3}}+\mathcal{L}_j^{n+\frac{2}{3}} \theta_j^{n+\frac{2}{3}}\right)\\
\theta_j^{n+1} &= \frac{1}{11}\left( 18  \theta_j^{n+\frac{2}{3}} - 9 \theta_j^{n+\frac{1}{3}} + 2 \theta_j^n + 2\delta\mathcal{L}_j^{n+1} \theta_j^{n+1}\right)
\end{align}
\end{subequations}

\subsection{Optimising for Performance}
The function $E(T, F)$ needs to be computed for every grid point $\left(F_j, t_n\right)$. The performance of the overall algorithm can be greatly improved by minimising the calls to the \texttt{pow} and \texttt{exp} functions as those are expensive. The quantities $D(F)$ and $\Gamma(F)$ are constant in time and can thus be cached between time-steps. A further improvement is to decompose $t_{n+1}$ as $t_{n}+\delta$, then 
\begin{equation}
e^{\rho\nu\alpha\Gamma t_{n+1}}=e^{\rho\nu\alpha\Gamma t_n}e^{\rho\nu\alpha\Gamma \delta}
\end{equation}
We can therefore just compute  $e_j = e^{\rho\nu\alpha\Gamma(F_j) \delta}$ for $j=0,...,J+1$ once, and at each step simply update $E$ as:
\begin{equation}
E_j^{n+1} = e_j E_j^{n} 
\end{equation}
%
with initial value $E_j^0=1$.
This can be easily extended to multiple time-step sizes used in multi-stage schemes.

For multi-stage schemes, it is also possible to consider $E$ as piecewise constant between full time-steps and thus to avoid its computation for fractions of time-steps. In our tests, this led to a slightly decreased accuracy and little performance gain. The increase in error was particularly visible for long term options and large time-steps. We did not make that approximation for the tests presented in the next section.

\section{Numerical Results}
\subsection{Oscillations}
\begin{figure}[htb]
  \begin{center}  
  \subfigure[$t_N=T$]{\label{fig:density_hagan_ran_500_5_0}
  \includegraphics[width=7cm]{density_hagan_theta_ran_500_5.eps}}
  \subfigure[Crank-Nicolson first 4 time steps with 5 time steps]{\label{fig:theta_hagan_cn_500_5}
\includegraphics[width=7cm]{theta_hagan_cn_500_5.eps}}
  \subfigure[Rannacher first 4 time steps with 5 time steps]{\label{fig:density_hagan_ran_500_5_5}
\includegraphics[width=7cm]{theta_hagan_ran_500_5.eps}}
  \subfigure[Lawson-Swayne first 4 time steps with 5 time steps]{\label{fig:density_hagan_lmg3_500_5_5}
\includegraphics[width=7cm]{theta_hagan_ls_500_5.eps}}
  \end{center}
     \caption{\label{fig:density_hagan_lmg2_500_10} Probability density in Hagan PDE using a total of 5 time-steps}
\end{figure}
With the same parameters as in section \ref{section_cn}, Figure \ref{fig:density_hagan_ran_500_5_0} shows a smooth positive probability density using only a total of 5 time-steps when Rannacher smoothing is applied to Crank-Nicolson. The density computed using second or third order Lawson-Morris-Gourlay (LMG2, LMG3), BDF2, Lawson-Swayne (LS), TR-BDF2 or Richardson extrapolation on implicit Euler (RE) would look very similar. Figure \ref{fig:density_hagan_ran_500_5_5} show no apparent oscillations in the first steps for the Rannacher scheme. BDF2 and LMG2 would look the same.  Lawson-Swayne shows a nearly imperceptible oscillation at the first step, and no more afterwards (Figure \ref{fig:density_hagan_lmg3_500_5_5}). TR-BDF2 and Bathe schemes behave similarly.
In contrast, Crank-Nicolson had strong oscillations visible at $T=\tau_{ex}$ with 40 time steps for the PDE in $Q$ and even stronger oscillations with 80 time steps for the PDE in $\theta$.

\subsection{Performance}
\subsubsection{Hagan Example}
With the same parameters as in section \ref{section_cn}, we look at the maximum error in the probability density with a varying number of time-steps compared to a Crank-Nicolson scheme with 5120 points for the rate dimension enough time-steps to ensure that $\Phi_{\theta} < 1$. 

\begin{figure}[htb]
  \begin{center}  
  \subfigure[Accuracy vs. number of time steps]{\label{fig:perf_hagan_500_steps}
  \includegraphics[width=7cm]{perf_theta_hagan_500_steps_all.eps}}
  \subfigure[Accuracy vs. time]{
\includegraphics[width=7cm]{perf_theta_hagan_500_time_all.eps}}
    \end{center}
     \caption{\label{fig:perf_hagan_500} Performance on Hagan example}
\end{figure}

%show convergence graph
Other tests we performed indicate that the implied volatility maximum error or even the at-the-money implied volatility error would lead to similar conclusions. Furthermore, a Black implied volatility with an absolute error under 0.1\% was achieved with only 3 time-steps for Bathe, 6 for Lawson-Swayne and TR-BDF2, 10 for LMG2, and 12 for BDF2 and RAN. Lawson-Swayne is the most efficient scheme on this problem, closely followed by TR-BDF2, Rannacher and BDF2.

Higher order schemes like BDF3, LMG3 or a third order Richardson extrapolation were found to be no better performing than their second order variation on this problem.

\subsubsection{Andreasen-Huge Example}
We consider the SABR parameters used in \citep{andreasen2011zabr}: $\alpha=0.0873, \beta=0.7, \rho=-0.48, \nu=0.47$ with a forward of $f=0.025$ and a maturity $\tau_{ex}=10.0$ and look at the maximum error in implied volatility between $0.2f$ and $2f$.

\begin{figure}[htb]
  \begin{center}  
  \subfigure[Accuracy vs. number of time steps]{\label{fig:perf_ah_500_steps}
  \includegraphics[width=7cm]{perf_vol_theta_ah_500_steps_all.eps}}
  \subfigure[Accuracy vs. time]{
\includegraphics[width=7cm]{perf_vol_theta_ah_500_time_all.eps}}
    \end{center}
     \caption{\label{fig:perf_ah_500} Performance on Andreasen-Huge example}
\end{figure}


%show convergence graph

Only 3 time-steps are enough to achieve a Black implied volatility accuracy better than 0.1\%  with Lawson-Swayne and Bathe schemes, 4 time-steps for TR-BDF2, 5 for LMG2, 12 for RAN and BDF2.

\subsection{Dupire Forward PDE}
The two different approaches result in the same smile, even with a relatively small number of time steps. With the Lawson Swayne finite difference method, the difference in implied volatility between the two approaches with 5 time-steps and $J=50, n_{sd}=4$ is always under 0.04\%. Figure \ref{fig:ah_densities_5_lv} displays the probability density computed by a numerical difference on the prices using the SABR parameters of Andreasen-Huge.
\begin{figure}[htb]
  \begin{center}  
  \subfigure[with 5 time-steps]{\label{fig:ah_densities_5_lv}
  \includegraphics[width=7cm]{ah_densities_5_lv.eps}}
  \subfigure[with 2 time-steps]{\label{fig:ah_densities_2_lv}
\includegraphics[width=7cm]{ah_densities_2_lv.eps}}
    \end{center}
     \caption{\label{fig:ah_densities_lv} Numerical Probability Density on Andreasen-Huge example}
\end{figure}

If one pushes the number of time steps smaller yet, then a difference appears in favour the the probability density approach (Figure \ref{fig:ah_densities_2_lv} with 2 steps).
\begin{figure}[htb]
  \begin{center}  
  \subfigure[with 5 time-steps]{\label{fig:ah_impliedvols_5_lv}
  \includegraphics[width=7cm]{ah_impliedvols_5_lv.eps}}
  \subfigure[with 2 time-steps]{\label{fig:ah_impliedvols_2_lv}
\includegraphics[width=7cm]{ah_impliedvols_2_lv.eps}}
    \end{center}
     \caption{\label{fig:ah_impliedvols_lv} Black implied volatility on Andreasen-Huge example}
\end{figure}

The probability density approach is more accurate with less time steps, and more stable. With only two time-steps, the Dupire approach leads to a large oscillation in probability density. As Lawson-Swayne is strongly L-stable, it disappears very quickly: with three time-steps or more.


\section{Conclusion}
It is possible to accurately compute option prices under the arbitrage free SABR approach with very few time-steps, even for long maturities. The Rannacher smoothing is a particularly simple and efficient way to improve accuracy significantly compared to Crank-Nicolson on this problem. BDF2 is even more simple and more efficient. Other schemes such as TR-BDF2 or Lawson-Swayne can further increase efficiency. In our experiments TR-BDF2 and Lawson-Swayne were robust and had similar stability and convergence properties.


Thus, with a careful choice of finite difference scheme, \citep{hagan2013arbitrage} is particularly competitive to the one step finite difference approach of \citep{andreasen2011zabr}.

\bibliographystyle{rAMF}
%\bibliographystyle{ieeetr}
\bibliography{lefloch_sabr_fdm}
\newpage
\appendix
\section{Example Code}
For illustration purpose, we detail here Octave code (also working with Matlab) for pricing vanilla options under the Arbitrage Free SABR model using Lawson-Swayne method.
%\lstset{caption={Scilab code for Arbitrage Free SABR with Lawson-Swayne solver}, label=scilab_code}
 \lstset{caption={makeTransformedSABRDensityLawsonSwayne.m - Matlab/Octave code computing the arbitrage free SABR density with Lawson-Swayne},
         basicstyle=\footnotesize\ttfamily, % Standardschrift
         %numbers=left,               % Ort der Zeilennummern
         numberstyle=\tiny,          % Stil der Zeilennummern
         %stepnumber=2,               % Abstand zwischen den Zeilennummern
         numbersep=5pt,              % Abstand der Nummern zum Text
         tabsize=2,                  % Groesse von Tabs
         extendedchars=true,         %
         breaklines=true,            % Zeilen werden Umgebrochen
         keywordstyle=\color{red},
    		frame=b,         
 %        keywordstyle=[1]\textbf,    % Stil der Keywords
 %        keywordstyle=[2]\textbf,    %
 %        keywordstyle=[3]\textbf,    %
 %        keywordstyle=[4]\textbf,   \sqrt{\sqrt{}} %
         stringstyle=\color{white}\ttfamily, % Farbe der String
         showspaces=false,           % Leerzeichen anzeigen ?
         showtabs=false,             % Tabs anzeigen ?
         xleftmargin=17pt,
         framexleftmargin=17pt,
         framexrightmargin=5pt,
         framexbottommargin=4pt,
         %backgroundcolor=\color{lightgray},
         showstringspaces=false      % Leerzeichen in Strings anzeigen ?        
 }
\begin{center}
\begin{lstlisting}
function [P,PL,PR, zm, zmin, zmax, h] = makeTransformedSABRDensityLawsonSwayne(alpha, beta, nu, rho, forward, T, N, timesteps, nd)
  %init h,F and Q
  zmin = -nd*sqrt(T); zmax = -zmin;
  if (beta < 1) 
    ybar = -forward^(1-beta)/(1-beta);
    zbar = -1/nu*log((sqrt(1-rho^2+(rho+nu*ybar/alpha)^2)-rho-nu*ybar/alpha)/(1-rho));
    if (zbar > zmin)
      zmin = zbar;
    end    
  end
  J = N-2;  h0 = (zmax-zmin)/(J);  
  j0 = int32((0-zmin)/h0);
  h = (0-zmin)/(double(j0)-0.5);  
  z = (0:(J+1))*h + zmin; zmax = z(J+2); zm = z - 0.5*h;
  ym = Y(alpha, nu, rho, zm); ymax = Y(alpha, nu, rho, zmax); ymin = Y(alpha, nu, rho, zmin);
  Fm = F(forward, beta, ym); Fmax = F(forward, beta, ymax); Fmin = F(forward, beta, ymin);
  Fm(1) = 2*Fmin-Fm(2); Fm(J+2)= 2*Fmax - Fm(J+1);
  Cm = sqrt(alpha^2+2*rho*alpha*nu*ym+nu^2*ym.^2).*Fm.^(beta);
  Cm(1) = Cm(2); Cm(J+2) = Cm(J+1); 
  Gammam = (Fm.^beta-forward^beta)./(Fm-forward); Gammam(j0+1) = beta/forward.^(1-beta);
  dt = T/timesteps; Em = ones(1,J+2);
  b = 1 - sqrt(2)/2; %Lawson Swayne param
  dt1 = dt*b; dt2 = dt*(1-2*b);
  Emdt1 = exp(rho*nu*alpha*Gammam*dt1); Emdt1(1)= Emdt1(2); Emdt1(J+2)= Emdt1(J+1);
  Emdt2 = exp(rho*nu*alpha*Gammam*dt2); Emdt2(1)= Emdt2(2); Emdt2(J+2)= Emdt2(J+1);
  PL = 0.0; PR = 0.0; P = zeros(J+2,1); P(j0+1,1)=1.0/h;
  for t = 1:timesteps
    Em = Em .* Emdt1; [P1, PL1, PR1] = solveStep(Fm, Cm, Em, dt1, h, P, PL, PR);
    Em = Em .* Emdt1; [P2, PL2, PR2] = solveStep(Fm, Cm, Em, dt1, h, P1, PL1, PR1);
    P=(sqrt(2)+1)*P2-sqrt(2)*P1;
    PL=(sqrt(2)+1)*PL2-sqrt(2)*PL1;
    PR=(sqrt(2)+1)*PR2-sqrt(2)*PR1;
    Em = Em .* Emdt2;
    %Ptotal = sum(h*P(2:J+1))+PL+PR
    %Ftotal = Fm(2:J+1)*P(2:J+1)*h+Fmin*PL+Fmax*PR
  end
end
function [P, PL, PR] = solveStep(Fm, Cm, Em, dt, h, P, PL, PR)
  frac = dt/(2*h); M = length(P);
  B(2:M-1) = 1.0 + frac*(Cm(2:M-1).*Em(2:M-1).*(1./(Fm(3:M)-Fm(2:M-1))+1./(Fm(2:M-1)-Fm(1:M-2))));
  C(2:M-1) = -frac* Cm(3:M).*Em(3:M)./(Fm(3:M)-Fm(2:M-1));
  A(1:M-2) = -frac* Cm(1:M-2).*Em(1:M-2)./(Fm(2:M-1)-Fm(1:M-2));
  B(1) = Cm(1)/(Fm(2)-Fm(1))*Em(1); C(1) = Cm(2)/(Fm(2)-Fm(1))*Em(2);
  B(M) = Cm(M)/(Fm(M)-Fm(M-1))*Em(M); A(M-1) = Cm(M-1)/(Fm(M)-Fm(M-1))*Em(M-1);  
  tri = diag(sparse(B))+diag(sparse(A),-1)+diag(sparse(C),1);
  P(1) = 0; P(M) = 0;
  P = tri\P;
  PL = PL + dt*Cm(2)/(Fm(2)-Fm(1))*Em(2)*P(2);
  PR = PR + dt*Cm(M-1)/(Fm(M)-Fm(M-1))*Em(M-1)*P(M-1);
end
function Y = Y(alpha, nu, rho, zm)
  Y = alpha/nu*(sinh(nu*zm)+rho*(cosh(nu*zm)-1));
end
function F = F(forward, beta, ym)
  F = (forward^(1-beta)+(1-beta)*ym).^(1/(1-beta));
end
\end{lstlisting}
\end{center}
The performance numbers in this paper come from an optimized Scala implementation, not from this Octave code.

\lstset{caption={priceCallTransformedSABRDensity.m - price a call option using Arbitrage Free SABR density}}
\begin{center}
\begin{lstlisting}
function p = priceCallTransformedSABRDensity(strike, alpha, beta, nu, rho, forward, T, P, PL,PR, zmin, zmax, h) 
  ystrike = (strike^(1-beta)-forward^(1-beta))/(1-beta);
  zstrike = -1/nu*log((sqrt(1-rho^2+(rho+nu*ystrike/alpha)^2)-rho-nu*ystrike/alpha)/(1-rho));
  if (zstrike <= zmin)
    p = forward-strike;
  else 
    if (zstrike >= zmax)
      p = 0;
    else
      Fmax = makeForward(alpha, beta, nu, rho, forward, zmax);
      p = (Fmax - strike) * PR;
      k0 = ceil((zstrike-zmin)/h);
      ztilde = zmin + k0*h;
      ftilde = makeForward(alpha, beta, nu, rho, forward, ztilde);
      term = ftilde - strike;
      if (term > 1e-5)
        zm = zmin + (k0-0.5) * h;
        Fm = makeForward(alpha, beta, nu, rho, forward, zm); 
        dFdz = (ftilde-Fm) / (ztilde - zm);
        p = p + 0.5 * term * term * P(k0+1)/dFdz;
      end
      k = k0+1:length(P)-2;
      zm = zmin + (k-0.5) * h;        
      Fm = makeForward(alpha, beta, nu, rho, forward, zm);     
      p = p + (Fm - strike) * h * P(k+1);
    end
  end
end
function F = makeForward(alpha, beta, nu, rho, forward, z) 
  y = alpha/nu*(sinh(nu*z)+rho*(cosh(nu*z)-1));
  F = (forward^(1-beta)+(1-beta)*y).^(1/(1-beta));
end
\end{lstlisting}
\end{center}

\section{Reference Implementation Values}
\begin{table}[h]
\begin{center}
\begin{tabular}{|c|c|c|c|c|}
\hline
Scheme & ATM price & $\theta(0)$ & $P_L$ & $P_R$\\
CN & 0.156536999912 & -75.391631075100 & 0.036151920718 & 0.000013551980\\
RAN & 0.149164032279 & 0.486588975088 & 0.037035726447 & 0.000022398224\\
BDF2 & 0.149369112191 & 0.478480554725 & 0.036571170375 & 0.000034872631\\
RE & 0.149622595233 & 0.482424676955 & 0.036971313630 & -0.000001793511\\
LMG2 & 0.149449019860 & 0.486727660232 & 0.037356585469 & -0.000003337903\\
LS & 0.149701955629 & 0.482422521405 & 0.036472664324 & 0.000010671927\\
TRBDF2 & 0.149703527234 & 0.482401023656 & 0.036469263805 & 0.000010658861\\
Bathe & 0.149631007454 & 0.486420051293 & 0.036725562889 & 0.000008443878\\
\hline
\end{tabular}
\caption{Sample values using 500 points and 5 time-steps, $\alpha=35\%, \beta=0.25, \rho=-10\%, \nu=100\%, T=1, f=1, n_{sd}=4, \delta=0.2, h=0.012018637349$}
\end{center}
\end{table} 
Checking the moments at every step is very useful way to validate a scheme's implementation in code. To support further validation we recorded specific values from our implementations as reference. The TR-BDF2 is using a value of $\alpha=2-\sqrt{2}$ whilst the RAN scheme is using Rannacher time-stepping for the first two full time-steps. Extrapolation methods like RE and LMG2 produce here a very low negative accumulated probability at the higher boundary: there are very small oscillations in those schemes around the higher boundary. In practice it is unlikely to matter, furthermore, they quickly converge to the true value when the number of time-steps is increased. 

\section{Convergence Tables}
\begin{table}[htb]
\begin{small}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
 $J$ & $N$ & ATM Value & Change & Ratio & Time(s)\\
\hline \multicolumn{6}{|c|}{CN} \\ \hline
 80 & 5 & 38.92945097 & NaN & NaN & 1.1e-04\\
 160 & 10 & 37.13441397 & -1.8e+00 & NaN & 3.0e-04\\
 320 & 20 & 37.42600113 & 2.9e-01 & -6.2 & 7.8e-04\\
 640 & 40 & 37.57545976 & 1.5e-01 & 2.0 & 2.1e-03\\
 1280 & 80 & 37.65103999 & 7.6e-02 & 2.0 & 7.3e-03\\
 2560 & 160 & 37.68906248 & 3.8e-02 & 2.0 & 2.7e-02\\
\hline \multicolumn{6}{|c|}{RAN} \\ \hline
 80 & 5 & 37.59281281 & NaN & NaN & 1.4e-04\\
 160 & 10 & 37.69385914 & 1.0e-01 & NaN & 2.9e-04\\
 320 & 20 & 37.71890369 & 2.5e-02 & 4.0 & 6.8e-04\\
 640 & 40 & 37.72510265 & 6.2e-03 & 4.0 & 2.2e-03\\
 1280 & 80 & 37.72664749 & 1.5e-03 & 4.0 & 7.6e-03\\
 2560 & 160 & 37.72703321 & 3.9e-04 & 4.0 & 2.7e-02\\
\hline \multicolumn{6}{|c|}{BDF2} \\ \hline
 80 & 5 & 37.64496421 & NaN & NaN & 9.7e-05\\
 160 & 10 & 37.70648716 & 6.2e-02 & NaN & 2.1e-04\\
 320 & 20 & 37.72178602 & 1.5e-02 & 4.0 & 7.3e-04\\
 640 & 40 & 37.72578924 & 4.0e-03 & 3.8 & 2.1e-03\\
 1280 & 80 & 37.72681485 & 1.0e-03 & 3.9 & 7.3e-03\\
 2560 & 160 & 37.72707451 & 2.6e-04 & 3.9 & 2.8e-02\\
\hline \multicolumn{6}{|c|}{RE} \\ \hline
 80 & 5 & 37.70951734 & NaN & NaN & 1.8e-04\\
 160 & 10 & 37.72310519 & 1.4e-02 & NaN & 4.2e-04\\
 320 & 20 & 37.72621751 & 3.1e-03 & 4.4 & 1.6e-03\\
 640 & 40 & 37.72693472 & 7.2e-04 & 4.3 & 5.5e-03\\
 1280 & 80 & 37.72710615 & 1.7e-04 & 4.2 & 2.0e-02\\
 2560 & 160 & 37.72714796 & 4.2e-05 & 4.1 & 7.2e-02\\
\hline
\end{tabular}
\begin{tabular}{|c|c|c|c|}
\hline
 ATM Value & Change & Ratio & Time(s)\\
\hline \multicolumn{4}{|c|}{LMG2} \\ \hline
 37.66503968 & NaN & NaN & 1.4e-04\\
 37.70865944 & 4.4e-02 & NaN & 3.9e-04\\
 37.72199774 & 1.3e-02 & 3.3 & 1.3e-03\\
 37.72578272 & 3.8e-03 & 3.5 & 4.9e-03\\
 37.72680412 & 1.0e-03 & 3.7 & 1.8e-02\\
 37.72707055 & 2.7e-04 & 3.8 & 7.1e-02\\
\hline \multicolumn{4}{|c|}{LMG3} \\ \hline
 37.70255505 & NaN & NaN & 1.8e-04\\
 37.72145184 & 1.9e-02 & NaN & 5.7e-04\\
 37.72587154 & 4.4e-03 & 4.3 & 2.0e-03\\
 37.72686398 & 9.9e-04 & 4.5 & 7.6e-03\\
 37.72709114 & 2.3e-04 & 4.4 & 2.9e-02\\
 37.72714460 & 5.3e-05 & 4.2 & 1.2e-01\\
\hline \multicolumn{4}{|c|}{LS} \\ \hline
 37.72979145 & NaN & NaN & 1.2e-04\\
 37.72762970 & -2.2e-03 & NaN & 2.9e-04\\
 37.72729564 & -3.3e-04 & 6.5 & 9.5e-04\\
 37.72719717 & -9.8e-05 & 3.4 & 3.4e-03\\
 37.72717084 & -2.6e-05 & 3.7 & 1.2e-02\\
 37.72716402 & -6.8e-06 & 3.9 & 4.9e-02\\
\hline \multicolumn{4}{|c|}{TRBDF2} \\ \hline
 37.73019364 & NaN & NaN & 1.6e-04\\
 37.72772657 & -2.5e-03 & NaN & 3.0e-04\\
 37.72731963 & -4.1e-04 & 6.1 & 9.5e-04\\
 37.72720314 & -1.2e-04 & 3.5 & 3.5e-03\\
 37.72717233 & -3.1e-05 & 3.8 & 1.3e-02\\
 37.72716439 & -7.9e-06 & 3.9 & 5.0e-02\\
\hline
\end{tabular}
\end{small}
\caption{Convergence of at-the-money implied volatility using $\alpha=35\%, \beta=0.25, \rho=-10\%, \nu=100\%, T=1, f=1, n_{sd}=4$}
\end{table} 

\end{document}
